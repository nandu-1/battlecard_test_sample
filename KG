import pdfplumber
import os

def extract_text_from_files(folder_path):
    text_data = ""
    for file in os.listdir(folder_path):
        if file.endswith(".txt"):
            with open(os.path.join(folder_path, file), "r", encoding="utf-8") as f:
                text_data += f.read() + "\n"
        elif file.endswith(".pdf"):
            with pdfplumber.open(os.path.join(folder_path, file)) as pdf:
                for page in pdf.pages:
                    text_data += page.extract_text() + "\n"
    return text_data

call_log_text = extract_text_from_files("call_logs_folder")


import spacy
import networkx as nx

nlp = spacy.load("en_core_web_sm")

def extract_entities(text):
    G = nx.Graph()
    doc = nlp(text)

    for ent in doc.ents:
        if ent.label_ == "ORG":  # Organization/Company
            G.add_node(ent.text, entity_type="Company")
        elif ent.label_ == "PERSON":  # Person Name
            G.add_node(ent.text, entity_type="Person")

    return G

# Build the Knowledge Graph
KG = extract_entities(call_log_text)

print("Entities in KG:", KG.nodes(data=True))




import re

def extract_amounts_and_accounts(text, G):
    amount_pattern = r"(?i)(?:Rs|INR|USD|₹|\$)\s?\d{1,3}(?:,\d{3})*(?:\.\d{1,2})?"  # Detects ₹500, Rs 5,000, $100.50
    account_pattern = r"(?i)(?:(?:account(?: ending in| number| no| for the| linked to)?)\s*(\d{4,16}))"

    amounts = re.findall(amount_pattern, text)
    accounts = re.findall(account_pattern, text)

    for i, amount in enumerate(amounts, start=1):
        G.add_node(f"amount{i}", entity_type="Amount", original_value=amount)

    for i, account in enumerate(accounts, start=1):
        G.add_node(f"account{i}", entity_type="Account", original_value=account)

    return G

# Update KG with Amounts & Account Numbers
KG = extract_amounts_and_accounts(call_log_text, KG)



from fuzzywuzzy import process

def mask_entities(text, G, entity_type, prefix):
    masked_text = text
    entity_count = 1
    mapping = {}

    for node in G.nodes(data=True):
        if node[1].get("entity_type") == entity_type:
            original_name = node[0]
            if original_name not in mapping:
                mapping[original_name] = f"{prefix}{entity_count}"
                entity_count += 1

            pattern = re.compile(r'\b' + re.escape(original_name) + r'\b', re.IGNORECASE)
            masked_text = re.sub(pattern, mapping[original_name], masked_text)

    return masked_text, mapping

# Mask Companies
masked_text, company_mapping = mask_entities(call_log_text, KG, "Company", "company")

# Mask Persons
masked_text, person_mapping = mask_entities(masked_text, KG, "Person", "person")

# Mask Amounts
for node in KG.nodes(data=True):
    if node[1].get("entity_type") == "Amount":
        masked_text = masked_text.replace(node[1]["original_value"], node[0])

# Mask Account Numbers
for node in KG.nodes(data=True):
    if node[1].get("entity_type") == "Account":
        masked_text = masked_text.replace(node[1]["original_value"], node[0])

print("Masked Call Log:\n", masked_text)


import pickle

with open("knowledge_graph.pkl", "wb") as f:
    pickle.dump(KG, f)

with open("knowledge_graph.pkl", "rb") as f:
    KG = pickle.load(f)

# Mask new call logs using the existing KG!
new_log_text = "Amazon paid Rs 10,000 to John Doe. Account No: 123456789012."
masked_text, _ = mask_entities(new_log_text, KG, "Company", "company")
masked_text, _ = mask_entities(masked_text, KG, "Person", "person")

print("Masked New Call Log:\n", masked_text)

import re

def remove_dates(text):
    # Regex pattern to remove dates
    date_pattern = r"\b(\d{2}\/\d{2,4})\b|\b(\d{4}\/\d{2})\b"
    
    # Replace all matching date patterns with an empty string
    cleaned_text = re.sub(date_pattern, "", text)
    
    return cleaned_text
